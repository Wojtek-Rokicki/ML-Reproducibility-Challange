{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# !pip install git+https://github.com/fkunstner/dataset-downloader.git\n",
    "import dsdl\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = \"/root/ML-Reproducibility-Challange/\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets, methods initialization and help functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASETS = ['a1a', 'mushrooms', 'a6a', 'w1a', 'w5a', 'ionosphere']\n",
    "METHODS = ['SGD', 'AdaSpider', 'Spider', 'SpiderBoost', 'SVRG', 'AdaGrad', 'AdaSVRG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dataset_name in DATASETS:\n",
    "#     X, y = get_data(dataset_name)\n",
    "#     pd.DataFrame(np.c_[X, y]).to_csv(f\"{dataset_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.optimizers.Optimizer import Optimizer\n",
    "\n",
    "def get_data(dataset_name: str):\n",
    "    \"\"\"\n",
    "    :param dataset_name: Name of the dataset from dsdl module.\n",
    "    :return: (X, y) train and target data.\n",
    "    \"\"\"\n",
    "    ds = dsdl.load(dataset_name)\n",
    "    X, y = ds.get_train()\n",
    "    X = X.toarray()\n",
    "    y = y.reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def build_model(X, y):\n",
    "    \"\"\"\n",
    "    Joins weights\n",
    "    :param X: shape=(N, D). Train data\n",
    "    :param y: shape=(N, 1). Target data\n",
    "    :return: shape=(N, D+1). Built model for logistic regression.\n",
    "    \"\"\"\n",
    "    return np.c_[np.zeros((y.shape[0], 1)), X]\n",
    "\n",
    "def get_initial_weights(tx):\n",
    "    \"\"\"\n",
    "    Returns weights initialized from the uniform distribution [0, 1].\n",
    "    :param tx: shape=(N, D). Build model\n",
    "    :return: shape=(D, 1) Initial weights\n",
    "    \"\"\"\n",
    "    np.random.seed(2022)\n",
    "    return np.zeros(shape=(tx.shape[1], 1))\n",
    "\n",
    "def test_method(method: Optimizer,\n",
    "                initial_weights,\n",
    "                tx,\n",
    "                y,\n",
    "                max_iter: int,\n",
    "                *parameter):\n",
    "        \"\"\"\n",
    "        :param method: Optimization method implementation from src optimizers module.\n",
    "        :param dataset_name: Name of the dataset from dsdl module.\n",
    "        :param max_iter: Number of iterations to test.\n",
    "        :param parameters optional: Dataclass containing parameters used int optimization method.\n",
    "        :return: List of gradients from optimization method.\n",
    "        \"\"\"\n",
    "        gradients, loss = method.optimize(initial_weights, tx, y, max_iter)\n",
    "        return [np.linalg.norm(grad, 2) for grad in gradients], loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.optimizers.SGD import SGD\n",
    "from src.optimizers.AdaSpider import AdaSpider\n",
    "from src.optimizers.Spider import Spider\n",
    "from src.optimizers.SpiderBoost import SpiderBoost\n",
    "from src.optimizers.SVRG import SVRG\n",
    "from src.optimizers.AdaGrad import AdaGrad\n",
    "from src.optimizers.AdaSVRG import AdaSVRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_ORACLE_CALLS = 10\n",
    "\n",
    "METHODS = [\n",
    "    SGD(lambda_=0.0001, q=N_ORACLE_CALLS),\n",
    "    AdaSpider(q=N_ORACLE_CALLS),\n",
    "    Spider(n_0 = 0.0001, epsilon=0.0001, q=N_ORACLE_CALLS),\n",
    "    SpiderBoost(q=N_ORACLE_CALLS),\n",
    "    SVRG(lambda_=0.0001, q=N_ORACLE_CALLS),\n",
    "    AdaGrad(lambda_=0.0001, epsilon= 0.0001, q=N_ORACLE_CALLS),\n",
    "    AdaSVRG(lambda_=0.0001, q=N_ORACLE_CALLS)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Methods testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run 2 # 20 mins on 8 cpu avs ml.c5.2xlarge\n",
    "# run 1 # 1 hour later on the 4 cpu machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset a1a\n",
      "Method SGD\n",
      "Method AdaSpider\n",
      "Method Spider\n",
      "Method SpiderBoost\n",
      "Method SVRG\n",
      "Method AdaGrad\n",
      "Method AdaSVRG\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 10000\n",
    "N_RUNS = 5\n",
    "\n",
    "all_gradients = []\n",
    "\n",
    "datasets_data = {}\n",
    "for i, dataset_name in enumerate(DATASETS):\n",
    "\n",
    "    print(\"Dataset\", dataset_name)\n",
    "\n",
    "    X, y = get_data(dataset_name)\n",
    "    tx = build_model(X, y)\n",
    "    initial_weights = get_initial_weights(tx)\n",
    "\n",
    "    methods_data = {}\n",
    "    for method, n_runs in zip(METHODS, [5,1,1,1,1,1,5]):\n",
    "        print(\"Method\", method.name)\n",
    "\n",
    "        gradients_5_runs = list()\n",
    "        for _ in range(n_runs):\n",
    "            gradients, _ = test_method(method, initial_weights, tx, y, ITERATIONS)\n",
    "            gradients_5_runs.append(gradients)\n",
    "        gradients_mean = np.mean(gradients_5_runs, axis=0)\n",
    "\n",
    "        stddev = np.std(gradients_5_runs, axis=0)\n",
    "        lower = gradients_mean - stddev\n",
    "        upper = gradients_mean + stddev\n",
    "\n",
    "        methods_data[method.name] = {\n",
    "            \"gradient_mean\": list(gradients_mean),\n",
    "            \"lower\": list(lower),\n",
    "            \"upper\": list(upper),\n",
    "            \"n_runs\": N_RUNS,\n",
    "            \"n_iterations\": ITERATIONS\n",
    "        }\n",
    "        datasets_data[dataset_name] = methods_data\n",
    "\n",
    "    break  # plot single dataset\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../results/run_3.json', 'w') as file:\n",
    "    json.dump(datasets_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean length of gradients\n",
    "print(\"DONE\")\n",
    "min_length = None\n",
    "for key, val in datasets_data['a1a'].items():\n",
    "    current_length = len(val['gradient_mean'])\n",
    "    if min_length is None:\n",
    "        min_length = current_length\n",
    "    elif min_length > current_length:\n",
    "        min_length = current_length\n",
    "min_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Results plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_LABEL = \"Stochastic oracle calls\"\n",
    "Y_LABEL = \"||\\u0394f(x)||^2\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), sharey=False, sharex=False)  # 3, 2\n",
    "\n",
    "for i, dataset_name in enumerate(DATASETS):\n",
    "    print(\"Dataset\", dataset_name)\n",
    "\n",
    "    methods_data = datasets_data[dataset_name]\n",
    "\n",
    "    # sbplt = ax[i%3, i%2]\n",
    "    sbplt = ax\n",
    "\n",
    "    for method_name, method_data in methods_data.items():\n",
    "        print(\"Method\", method_name)\n",
    "\n",
    "        gradients_mean = method_data['gradient_mean'][10:]\n",
    "        lower = method_data['lower'][10:]\n",
    "        upper = method_data['upper'][10:]\n",
    "        n_iterations = method_data['n_iterations']\n",
    "\n",
    "        sbplt.plot(gradients_mean[:min_length], label=method_name)\n",
    "        sbplt.fill_between(list(range(len(gradients_mean[:min_length]))), lower[:min_length], upper[:min_length], alpha=0.25,\n",
    "                           facecolor='red', edgecolor='red')\n",
    "\n",
    "    sbplt.set_xscale('log')\n",
    "    sbplt.set_yscale('log')\n",
    "    sbplt.set_title(dataset_name)\n",
    "    sbplt.set_xlabel(X_LABEL)\n",
    "    sbplt.set_ylabel(Y_LABEL)\n",
    "    sbplt.legend(loc='lower left', fontsize='small')\n",
    "\n",
    "    break  # plot single dataset\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "fig.savefig(f'../results/tests_logistic_regression_run_3.jpg', dpi=300)\n",
    "\n",
    "# plot_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Parameters sweep tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REDUCTION_STEP = 10\n",
    "\n",
    "METHODS = [\n",
    "    SGD(lambda_=0.01, q=REDUCTION_STEP),\n",
    "    # AdaSpider(q=REDUCTION_STEP),\n",
    "    Spider(n_0 = 1, epsilon=0.01, q=REDUCTION_STEP),\n",
    "    SpiderBoost(q=REDUCTION_STEP),\n",
    "    SVRG(lambda_=0.001, q=REDUCTION_STEP),\n",
    "    AdaGrad(lambda_=0.5, epsilon= 0.00001, q=REDUCTION_STEP),\n",
    "    AdaSVRG(lambda_=0.1, q=REDUCTION_STEP)\n",
    "]\n",
    "\n",
    "DF_COLUMNS = ['method_name', 'loss', 'parameters']\n",
    "df = pd.DataFrame(columns=DF_COLUMNS)\n",
    "\n",
    "dataset_name = 'a1a'\n",
    "ITERATIONS = 1000\n",
    "print(\"Dataset\", dataset_name, \"Iterations: \", ITERATIONS)\n",
    "\n",
    "powers = np.array([range(-5, 0)], dtype=float)\n",
    "parameters = 10**powers.flatten()\n",
    "\n",
    "X, y = get_data(dataset_name)\n",
    "tx = build_model(X, y)\n",
    "initial_weights = get_initial_weights(tx)\n",
    "\n",
    "for method in METHODS:\n",
    "    print(\"Method\", method.name)\n",
    "    if method.n_params_to_tune == 2:\n",
    "        for param in list(product(parameters, parameters)):\n",
    "            method.set_params(param[0], param[1])\n",
    "            _, losses = test_method(method, initial_weights, tx, y, ITERATIONS)\n",
    "            df = df.append(dict(zip(DF_COLUMNS, [method.name, np.sum(losses), str(param)])), ignore_index=True)\n",
    "\n",
    "    elif method.n_params_to_tune == 1:\n",
    "        for param in parameters:\n",
    "            method.set_params(param)\n",
    "            _, losses = test_method(method, initial_weights, tx, y, ITERATIONS)\n",
    "            df = df.append(dict(zip(DF_COLUMNS, [method.name, np.sum(losses), str(param)])), ignore_index=True)\n",
    "    else:\n",
    "        _, losses = test_method(method, initial_weights, tx, y, ITERATIONS)\n",
    "        df = df.append(dict(zip(DF_COLUMNS, [method.name, np.sum(losses), str(param)])), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"parameters_sweep_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaGrad</th>\n",
       "      <td>3432.160706</td>\n",
       "      <td>(0.0001, 0.0001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaSVRG</th>\n",
       "      <td>851480.257577</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>902.078086</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVRG</th>\n",
       "      <td>1148.117316</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spider</th>\n",
       "      <td>2270.080086</td>\n",
       "      <td>(0.0001, 0.0001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpiderBoost</th>\n",
       "      <td>2203.122416</td>\n",
       "      <td>(0.1, 0.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      loss        parameters\n",
       "method_name                                 \n",
       "AdaGrad        3432.160706  (0.0001, 0.0001)\n",
       "AdaSVRG      851480.257577            0.0001\n",
       "SGD             902.078086            0.0001\n",
       "SVRG           1148.117316            0.0001\n",
       "Spider         2270.080086  (0.0001, 0.0001)\n",
       "SpiderBoost    2203.122416        (0.1, 0.1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loss'] = df['loss'].abs()\n",
    "df.groupby('method_name').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# METHODS = ['AdaSpider', 'Spider']\n",
    "# ITERATIONS = 100\n",
    "#\n",
    "# def plot_data():\n",
    "#     # Write your code to make 4x4 panel here\n",
    "#     X_LABEL = \"Stochastic oracle calls\"\n",
    "#     Y_LABEL = \"||\\u0394f(x)||^2\"\n",
    "#\n",
    "#     fig, ax = plt.subplots(3,2,figsize=(16,16), sharey=False, sharex=False)\n",
    "#\n",
    "#     for i, dataset_name in enumerate(DATASETS):\n",
    "#         sbplt = ax[i%3, i%2]\n",
    "#         print(dataset_name)\n",
    "#         for method in METHODS:\n",
    "#             if method == \"Spider\":\n",
    "#                 spider_params = SpiderParam(100, 5, 0.05)\n",
    "#                 gradients = test_method(Spider, dataset_name, ITERATIONS, spider_params)\n",
    "#             else:\n",
    "#                 gradients = test_method(ADASpider, dataset_name, ITERATIONS)\n",
    "#             gradients = [np.linalg.norm(grad, 2) for grad in gradients]\n",
    "#             sbplt.plot(gradients, label=method)\n",
    "#\n",
    "#         sbplt.set_xscale('log')\n",
    "#         sbplt.set_title(dataset_name)\n",
    "#         sbplt.set_xlabel(X_LABEL)\n",
    "#         sbplt.set_ylabel(Y_LABEL)\n",
    "#         sbplt.legend(loc='lower left')\n",
    "#\n",
    "#         break  # plot single dataset\n",
    "#\n",
    "#     fig.tight_layout(pad=2.0)\n",
    "#     # fig.savefig('../results/tests_logistic_regression.jpg', dpi=150)\n",
    "#\n",
    "# plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Sep  3 2022, 00:18:47) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bddca6f205aebd86508050b416256222382b98c4aa05f61f33afbd3d1facfd66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
