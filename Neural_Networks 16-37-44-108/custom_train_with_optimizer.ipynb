{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6pkpdYAmZh",
        "outputId": "dfdf8e0a-3ca0-4f23-b0fe-f990dec7343b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "# Import the tensorflow\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "pLcPN_XFUMOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a loss function.\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the training dataset.\n",
        "# import numpy as np\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# x_train = np.reshape(x_train, (-1, 784))\n",
        "# x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# Reserve 10,000 samples for validation.\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "# batched_train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "# Define metric for the validation\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "T2St_7oOUZeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add7f38d-1f9b-4e92-de2c-0325de3ff97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy as cp\n",
        "\n",
        "def get_model_weights(model):\n",
        "  w = []\n",
        "  for l in model.layers:\n",
        "    w.append(cp.deepcopy(l.get_weights()))\n",
        "  return w\n",
        "  \n",
        "def set_model_weights(model, weights):\n",
        "  for i, l in enumerate(model.layers):\n",
        "    l.set_weights(weights[i])\n",
        "\n",
        "def compute_sgd(x_train, y_train, loss_fn, w):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(x_train, training=True)\n",
        "      loss_value = loss_fn(y_train, logits)\n",
        "  grads = tape.gradient(loss_value, w)\n",
        "  return grads, loss_value\n",
        "\n",
        "def spider_boost_training(model, loss_fn, x_train, y_train, q, batch_size = 64, epochs=50):\n",
        "  \n",
        "  lipshitz_const = 200  # np.linalg.norm(tx, 'fro') ** 2\n",
        "  learning_rate = 1/(2*lipshitz_const)\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "  grads_h = []\n",
        "  \n",
        "  # w = get_model_weights(model)\n",
        "  # w_h = [w] \n",
        "  w_h = [model.trainable_weights]\n",
        "\n",
        "  n = len(y_train)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      if epoch%10 == 0:\n",
        "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "      # Compute full GD each q'th epoch\n",
        "      if epoch % q == 0:\n",
        "        grads, loss_value = compute_sgd(x_train, y_train, loss_fn, model.trainable_weights)\n",
        "      # Otherwise make calculate SGD\n",
        "      else:\n",
        "        print(w_h[epoch] is w_h[epoch-1])\n",
        "        idxs = np.random.choice(n, batch_size, replace=True)\n",
        "        x_train_batch = x_train[idxs]\n",
        "        y_train_batch = y_train[idxs]\n",
        "\n",
        "        # grads, loss_value = compute_sgd(x_train_batch, y_train_batch, loss_fn, model.trainable_weights)\n",
        "        # set_model_weights(model, w_h[epoch-1])\n",
        "        # prev_grads, _ = compute_sgd(x_train_batch, y_train_batch, loss_fn, model.trainable_weights)\n",
        "        grads, loss_value = compute_sgd(x_train_batch, y_train_batch, loss_fn, model.trainable_weights)\n",
        "        prev_grads, _ = compute_sgd(x_train_batch, y_train_batch, loss_fn, w_h[epoch-1])\n",
        "\n",
        "        grads = [(grad - prev_grad + grad_h)/len(idxs) for grad, prev_grad, grad_h in zip(grads, prev_grads, grads_h[epoch-1])]\n",
        "\n",
        "      # set_model_weights(model, w_h[epoch])\n",
        "\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "      grads_h.append(grads)\n",
        "\n",
        "      # w = get_model_weights(model)\n",
        "      # w_h.append(w)\n",
        "      w_h.append(model.trainable_weights)\n",
        "      if epoch%10 == 0:\n",
        "        print(\n",
        "            \"Training loss at epoch %d: %.4f\"\n",
        "            % (epoch, float(loss_value))\n",
        "        )"
      ],
      "metadata": {
        "id": "5cL85KgjUpqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spider_boost_training(model, loss_fn, x_train, y_train, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2PViLSVYGub",
        "outputId": "543c038e-c6cd-4bae-c361-216632185e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss at epoch 0: 186.7522\n",
            "\n",
            "Start of epoch 1\n",
            "False\n",
            "Training loss at epoch 1: 55.0638\n",
            "\n",
            "Start of epoch 2\n",
            "False\n",
            "Training loss at epoch 2: 48.4164\n",
            "\n",
            "Start of epoch 3\n",
            "False\n",
            "Training loss at epoch 3: 77.9045\n",
            "\n",
            "Start of epoch 4\n",
            "False\n",
            "Training loss at epoch 4: 58.0486\n",
            "\n",
            "Start of epoch 5\n",
            "False\n",
            "Training loss at epoch 5: 70.5925\n",
            "\n",
            "Start of epoch 6\n",
            "False\n",
            "Training loss at epoch 6: 72.3616\n",
            "\n",
            "Start of epoch 7\n",
            "False\n",
            "Training loss at epoch 7: 54.6220\n",
            "\n",
            "Start of epoch 8\n",
            "False\n",
            "Training loss at epoch 8: 54.3897\n",
            "\n",
            "Start of epoch 9\n",
            "False\n",
            "Training loss at epoch 9: 67.2313\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss at epoch 10: 63.4636\n",
            "\n",
            "Start of epoch 11\n",
            "False\n",
            "Training loss at epoch 11: 40.2330\n",
            "\n",
            "Start of epoch 12\n",
            "False\n",
            "Training loss at epoch 12: 41.4355\n",
            "\n",
            "Start of epoch 13\n",
            "False\n",
            "Training loss at epoch 13: 46.4037\n",
            "\n",
            "Start of epoch 14\n",
            "False\n",
            "Training loss at epoch 14: 30.1770\n",
            "\n",
            "Start of epoch 15\n",
            "False\n",
            "Training loss at epoch 15: 33.1872\n",
            "\n",
            "Start of epoch 16\n",
            "False\n",
            "Training loss at epoch 16: 35.1767\n",
            "\n",
            "Start of epoch 17\n",
            "False\n",
            "Training loss at epoch 17: 40.0605\n",
            "\n",
            "Start of epoch 18\n",
            "False\n",
            "Training loss at epoch 18: 34.4760\n",
            "\n",
            "Start of epoch 19\n",
            "False\n",
            "Training loss at epoch 19: 37.0946\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss at epoch 20: 35.1797\n",
            "\n",
            "Start of epoch 21\n",
            "False\n",
            "Training loss at epoch 21: 11.7227\n",
            "\n",
            "Start of epoch 22\n",
            "False\n",
            "Training loss at epoch 22: 12.6404\n",
            "\n",
            "Start of epoch 23\n",
            "False\n",
            "Training loss at epoch 23: 12.5640\n",
            "\n",
            "Start of epoch 24\n",
            "False\n",
            "Training loss at epoch 24: 6.6930\n",
            "\n",
            "Start of epoch 25\n",
            "False\n",
            "Training loss at epoch 25: 14.9759\n",
            "\n",
            "Start of epoch 26\n",
            "False\n",
            "Training loss at epoch 26: 16.7161\n",
            "\n",
            "Start of epoch 27\n",
            "False\n",
            "Training loss at epoch 27: 12.5780\n",
            "\n",
            "Start of epoch 28\n",
            "False\n",
            "Training loss at epoch 28: 12.5614\n",
            "\n",
            "Start of epoch 29\n",
            "False\n",
            "Training loss at epoch 29: 12.0868\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss at epoch 30: 12.8707\n",
            "\n",
            "Start of epoch 31\n",
            "False\n",
            "Training loss at epoch 31: 6.5732\n",
            "\n",
            "Start of epoch 32\n",
            "False\n",
            "Training loss at epoch 32: 6.5687\n",
            "\n",
            "Start of epoch 33\n",
            "False\n",
            "Training loss at epoch 33: 5.4693\n",
            "\n",
            "Start of epoch 34\n",
            "False\n",
            "Training loss at epoch 34: 5.1896\n",
            "\n",
            "Start of epoch 35\n",
            "False\n",
            "Training loss at epoch 35: 6.2916\n",
            "\n",
            "Start of epoch 36\n",
            "False\n",
            "Training loss at epoch 36: 7.8716\n",
            "\n",
            "Start of epoch 37\n",
            "False\n",
            "Training loss at epoch 37: 6.2068\n",
            "\n",
            "Start of epoch 38\n",
            "False\n",
            "Training loss at epoch 38: 7.5458\n",
            "\n",
            "Start of epoch 39\n",
            "False\n",
            "Training loss at epoch 39: 4.9576\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss at epoch 40: 5.8977\n",
            "\n",
            "Start of epoch 41\n",
            "False\n",
            "Training loss at epoch 41: 4.4417\n",
            "\n",
            "Start of epoch 42\n",
            "False\n",
            "Training loss at epoch 42: 5.3079\n",
            "\n",
            "Start of epoch 43\n",
            "False\n",
            "Training loss at epoch 43: 5.1954\n",
            "\n",
            "Start of epoch 44\n",
            "False\n",
            "Training loss at epoch 44: 6.0844\n",
            "\n",
            "Start of epoch 45\n",
            "False\n",
            "Training loss at epoch 45: 3.9243\n",
            "\n",
            "Start of epoch 46\n",
            "False\n",
            "Training loss at epoch 46: 3.7648\n",
            "\n",
            "Start of epoch 47\n",
            "False\n",
            "Training loss at epoch 47: 3.1224\n",
            "\n",
            "Start of epoch 48\n",
            "False\n",
            "Training loss at epoch 48: 5.8025\n",
            "\n",
            "Start of epoch 49\n",
            "False\n",
            "Training loss at epoch 49: 4.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(val_dataset, model, metric):\n",
        "  # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = model(x_batch_val, training=False)\n",
        "        # Update val metrics\n",
        "        metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = metric.result()\n",
        "    metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))"
      ],
      "metadata": {
        "id": "r3KhK0SaajHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(val_dataset, model, val_acc_metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgARBIgeZhX5",
        "outputId": "0d6167e8-885c-4ff7-b7fb-2b36de5abd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.2678\n"
          ]
        }
      ]
    }
  ]
}